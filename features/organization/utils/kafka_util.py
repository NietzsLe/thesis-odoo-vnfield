# -*- coding: utf-8 -*-
#############################################################################
#
#    VN Field Contractor System 
#    Kafka Utility Class Ä‘á»ƒ produce vÃ  consume messages
#
#############################################################################

import json
import logging
from confluent_kafka import Producer, Consumer, KafkaError
from odoo import models, fields, api

_logger = logging.getLogger(__name__)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# â•             ğŸ“¡ KAFKA UTILITY CLASS                     â•
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class KafkaUtil(models.TransientModel):
    _name = 'vnfield.kafka.util'
    _description = 'Kafka Utility for Producer and Consumer Operations'

    @api.model
    def get_bootstrap_servers(self):
        """
        ğŸ“Š Get Bootstrap Server tá»« system parameters
        """
        return self.env['ir.config_parameter'].sudo().get_param(
            'vnfield.kafka.bootstrap_servers', 
            default='localhost:9092'
        )
    
    @api.model
    def get_consumer_group_id(self):
        """
        ğŸ¯ Get Consumer Group ID tá»« external_id cá»§a default contractor
        """
        try:
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ” FIND DEFAULT CONTRACTOR â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            default_contractor = self.env['vnfield.contractor'].search([
                ('is_default_contractor', '=', True)
            ], limit=1)
            
            if default_contractor and default_contractor.external_id:
                # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ—ï¸ BUILD GROUP ID WITH EXTERNAL_ID â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                base_group = self.env['ir.config_parameter'].sudo().get_param(
                    'vnfield.kafka.consumer_group_id', 
                    default='vnfield_cs_consumer'
                )
                return f"{base_group}_{default_contractor.external_id}"
            else:
                # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ âš ï¸ FALLBACK TO SYSTEM PARAMETER â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                _logger.warning('âš ï¸ No default contractor with external_id found, using system parameter')
                return self.env['ir.config_parameter'].sudo().get_param(
                    'vnfield.kafka.consumer_group_id', 
                    default='vnfield_cs_consumer'
                )
                
        except Exception as e:
            _logger.error(f'âŒ Error getting consumer group ID: {str(e)}')
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ›¡ï¸ SAFE FALLBACK â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            return self.env['ir.config_parameter'].sudo().get_param(
                'vnfield.kafka.consumer_group_id', 
                default='vnfield_cs_consumer'
            )
    
    @api.model
    def get_default_contractor_external_id(self):
        """
        ğŸ¢ Get external_id cá»§a default contractor
        
        Returns:
            int|None: External ID cá»§a default contractor hoáº·c None náº¿u khÃ´ng tÃ¬m tháº¥y
        """
        try:
            default_contractor = self.env['vnfield.contractor'].search([
                ('is_default_contractor', '=', True)
            ], limit=1)
            
            if default_contractor and default_contractor.external_id:
                return default_contractor.external_id
            else:
                _logger.warning('âš ï¸ No default contractor with external_id found')
                return None
                
        except Exception as e:
            _logger.error(f'âŒ Error getting default contractor external_id: {str(e)}')
            return None
    
    @api.model
    def get_consumer_timeout(self):
        """
        â±ï¸ Get Consumer Timeout tá»« system parameters
        """
        return float(self.env['ir.config_parameter'].sudo().get_param(
            'vnfield.kafka.consumer_timeout', 
            default='5.0'
        ))
    
    @api.model
    def get_max_messages(self):
        """
        ğŸ“Š Get Max Messages Per Consumption tá»« system parameters
        """
        return int(self.env['ir.config_parameter'].sudo().get_param(
            'vnfield.kafka.max_messages', 
            default='10'
        ))
    
    @api.model
    def get_producer_retries(self):
        """
        ğŸ”„ Get Producer Retries tá»« system parameters
        """
        return int(self.env['ir.config_parameter'].sudo().get_param(
            'vnfield.kafka.producer_retries', 
            default='3'
        ))
    
    @api.model
    def get_topic_prefix(self):
        """
        ğŸ“¡ Get Topic Prefix tá»« system parameters
        """
        return self.env['ir.config_parameter'].sudo().get_param(
            'vnfield.kafka.topic_prefix', 
            default='vnfield_cs'
        )
    
    @api.model
    def build_topic_name(self, base_name, include_contractor_id=False):
        """
        ğŸ—ï¸ Build topic name vá»›i prefix tá»« system parameters
        
        Args:
            base_name (str): Base topic name
            include_contractor_id (bool): CÃ³ include contractor external_id trong topic name khÃ´ng
            
        Returns:
            str: Formatted topic name vá»›i prefix (vÃ  contractor ID náº¿u Ä‘Æ°á»£c yÃªu cáº§u)
        """
        prefix = self.get_topic_prefix()
        
        if include_contractor_id:
            contractor_external_id = self.get_default_contractor_external_id()
            if contractor_external_id:
                return f"{prefix}.{contractor_external_id}.{base_name}"
            else:
                _logger.warning('âš ï¸ No contractor external_id available, using prefix only')
                return f"{prefix}.{base_name}"
        else:
            return f"{prefix}.{base_name}"
    
    @api.model
    def validate_topics(self, topics):
        """
        âœ… Validate topic names vÃ  ensure chÃºng lÃ  list
        
        Args:
            topics (str|list): Topic name hoáº·c list cá»§a topic names
            
        Returns:
            list: Validated list cá»§a topic names
        """
        if isinstance(topics, str):
            return [topics]
        elif isinstance(topics, list):
            return topics
        else:
            raise ValueError("Topics pháº£i lÃ  string hoáº·c list of strings")
    
    @api.model
    def produce(self, topic, message, headers=None):
        """
        ğŸ“¤ Produce message Ä‘áº¿n Kafka topic
        
        Args:
            topic (str): Kafka topic name
            message (dict): Message payload  
            headers (dict): Optional message headers
        
        Returns:
            bool: True náº¿u thÃ nh cÃ´ng, False náº¿u tháº¥t báº¡i
        """
        try:
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ”§ PRODUCER CONFIGURATION â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            contractor_external_id = self.get_default_contractor_external_id()
            client_id = f'{self.get_topic_prefix()}_producer'
            if contractor_external_id:
                client_id = f'{self.get_topic_prefix()}_{contractor_external_id}_producer'
            
            producer_config = {
                'bootstrap.servers': self.get_bootstrap_servers(),
                'client.id': client_id,
                'acks': 'all',
                'retries': self.get_producer_retries(),
                'retry.backoff.ms': 100,
                'delivery.timeout.ms': 30000,
                'request.timeout.ms': 25000
            }
            
            producer = Producer(producer_config)
            
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ“ MESSAGE PREPARATION â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            message_value = json.dumps(message, ensure_ascii=False, default=str)
            
            # Convert headers to list of tuples vá»›i UTF-8 encoding
            kafka_headers = []
            if headers:
                for key, value in headers.items():
                    kafka_headers.append((key, str(value).encode('utf-8')))
            
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ“¡ SEND MESSAGE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            def delivery_report(err, msg):
                """ğŸ“‹ Callback for delivery reports"""
                if err is not None:
                    _logger.error(f'âŒ Message delivery failed: {err}')
                else:
                    _logger.info(f'âœ… Message delivered to {msg.topic()} [{msg.partition()}]')
            
            producer.produce(
                topic=topic,
                value=message_value.encode('utf-8'),
                headers=kafka_headers,
                callback=delivery_report
            )
            
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â³ WAIT FOR DELIVERY â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            producer.flush(timeout=10)
            
            _logger.info(f'ğŸš€ Message sent to topic: {topic}')
            return True
            
        except Exception as e:
            _logger.error(f'âŒ Kafka produce error: {str(e)}')
            return False
    
    @api.model 
    def consume(self, topics, group_id=None, timeout=None, max_messages=None):
        """
        ğŸ“¥ Consume messages tá»« Kafka topics
        
        Args:
            topics (list): List cá»§a topic names Ä‘á»ƒ consume
            group_id (str): Consumer group ID (optional, sá»­ dá»¥ng system parameter náº¿u None)
            timeout (float): Timeout seconds cho polling (optional, sá»­ dá»¥ng system parameter náº¿u None)
            max_messages (int): Maximum sá»‘ messages Ä‘á»ƒ consume (optional, sá»­ dá»¥ng system parameter náº¿u None)
        
        Returns:
            list: List cá»§a consumed messages
        """
        messages = []
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ”§ PARAMETER RESOLUTION â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if group_id is None:
            group_id = self.get_consumer_group_id()
        if timeout is None:
            timeout = self.get_consumer_timeout()
        if max_messages is None:
            max_messages = self.get_max_messages()
        
        try:
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ”§ CONSUMER CONFIGURATION â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            contractor_external_id = self.get_default_contractor_external_id()
            client_id = f'{self.get_topic_prefix()}_consumer'
            if contractor_external_id:
                client_id = f'{self.get_topic_prefix()}_{contractor_external_id}_consumer'
            
            consumer_config = {
                'bootstrap.servers': self.get_bootstrap_servers(),
                'group.id': group_id,
                'client.id': client_id,
                'auto.offset.reset': 'earliest',
                'enable.auto.commit': True,
                'auto.commit.interval.ms': 1000,
                'session.timeout.ms': 30000,
                'heartbeat.interval.ms': 10000
            }
            
            consumer = Consumer(consumer_config)
            
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ“¡ SUBSCRIBE TO TOPICS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            consumer.subscribe(topics)
            _logger.info(f'ğŸ¯ Subscribed to topics: {topics} with group_id: {group_id}')
            _logger.info(f'ğŸ¢ Using contractor external_id: {contractor_external_id}' if contractor_external_id else 'âš ï¸ No contractor external_id found')
            
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ“¥ CONSUME MESSAGES â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            message_count = 0
            while message_count < max_messages:
                msg = consumer.poll(timeout=timeout)
                
                if msg is None:
                    _logger.info('â±ï¸ No more messages, timeout reached')
                    break
                    
                if msg.error():
                    if msg.error().code() == KafkaError._PARTITION_EOF:
                        _logger.info(f'ğŸ“„ End of partition reached: {msg.topic()} [{msg.partition()}]')
                        continue
                    else:
                        _logger.error(f'âŒ Consumer error: {msg.error()}')
                        break
                
                # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ”„ PROCESS MESSAGE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                try:
                    message_data = json.loads(msg.value().decode('utf-8'))
                    
                    # Extract headers
                    headers = {}
                    if msg.headers():
                        for key, value in msg.headers():
                            headers[key] = value.decode('utf-8') if value else None
                    
                    processed_message = {
                        'topic': msg.topic(),
                        'partition': msg.partition(),
                        'offset': msg.offset(),
                        'timestamp': msg.timestamp(),
                        'headers': headers,
                        'payload': message_data
                    }
                    
                    messages.append(processed_message)
                    message_count += 1
                    
                    _logger.info(f'ğŸ“¨ Consumed message from {msg.topic()}: {message_data}')
                    
                except json.JSONDecodeError as e:
                    _logger.error(f'âŒ JSON decode error: {str(e)}')
                    continue
                    
        except Exception as e:
            _logger.error(f'âŒ Kafka consume error: {str(e)}')
        
        finally:
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ”š CLEANUP â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            try:
                consumer.close()
                _logger.info('ğŸ”š Consumer closed successfully')
            except:
                pass
        
        _logger.info(f'ğŸ“Š Total consumed messages: {len(messages)}')
        return messages
    
    @api.model
    def test_connection(self):
        """
        ğŸ” Test Kafka connection Ä‘á»ƒ kiá»ƒm tra server availability
        
        Returns:
            dict: Connection test results
        """
        result = {
            'success': False,
            'message': '',
            'bootstrap_servers': self.get_bootstrap_servers(),
            'error_details': None
        }
        
        try:
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ§ª TEST PRODUCER CONNECTION â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            contractor_external_id = self.get_default_contractor_external_id()
            client_id = f'{self.get_topic_prefix()}_test_producer'
            if contractor_external_id:
                client_id = f'{self.get_topic_prefix()}_{contractor_external_id}_test_producer'
            
            producer_config = {
                'bootstrap.servers': self.get_bootstrap_servers(),
                'client.id': client_id,
                'socket.timeout.ms': 5000,
                'api.version.request.timeout.ms': 5000
            }
            
            producer = Producer(producer_config)
            
            # Test báº±ng cÃ¡ch request metadata
            metadata = producer.list_topics(timeout=5)
            
            if metadata and metadata.topics:
                result['success'] = True
                result['message'] = f'âœ… Káº¿t ná»‘i thÃ nh cÃ´ng Ä‘áº¿n Kafka server: {self.get_bootstrap_servers()}'
                result['available_topics'] = list(metadata.topics.keys())
                _logger.info(f"ğŸ¯ Kafka connection test successful: {len(metadata.topics)} topics available")
            else:
                result['message'] = 'âš ï¸ Káº¿t ná»‘i thÃ nh cÃ´ng nhÆ°ng khÃ´ng cÃ³ topics nÃ o'
                
        except Exception as e:
            result['message'] = f'âŒ KhÃ´ng thá»ƒ káº¿t ná»‘i Ä‘áº¿n Kafka server: {str(e)}'
            result['error_details'] = str(e)
            _logger.error(f"âŒ Kafka connection test failed: {str(e)}")
            
        return result

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# â•           ğŸ—ï¸ SYMBOL DEPENDENCIES ANALYSIS              â•
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

"""
ğŸ“‹ DEPENDENCIES ÄÆ¯á»¢C Sá»¬ Dá»¤NG TRONG FILE NÃ€Y:

ğŸ”— PYTHON DEPENDENCIES:
- json: JSON serialization/deserialization cho message payload
- logging: Error vÃ  info logging cho debugging vÃ  monitoring
- confluent_kafka.Producer: Kafka message producer vá»›i delivery reports
- confluent_kafka.Consumer: Kafka message consumer vá»›i auto-commit
- confluent_kafka.KafkaError: Error handling cho connection vÃ  message errors

ğŸ”— ODOO DEPENDENCIES:
- odoo.models.TransientModel: Base class cho utility model khÃ´ng lÆ°u vÃ o database
- odoo.fields: Field definitions (reserved cho future enhancements)
- odoo.api: API decorators (@api.model) cho static method calls
- self.env['ir.config_parameter']: System parameters access cho configuration

ğŸ”— KAFKA INTEGRATION DEPENDENCIES:
- Bootstrap servers: Connection configuration Ä‘áº¿n Kafka cluster tá»« system parameters
- Producer configuration: Message delivery settings vá»›i acks=all vÃ  retries
- Consumer configuration: Message consumption settings vá»›i auto-commit
- Topic management: Subscribe vÃ  produce to topics vá»›i naming conventions
- Message formatting: JSON payload vá»›i UTF-8 encoding vÃ  custom headers
- Connection testing: Metadata requests Ä‘á»ƒ validate server availability

ğŸ”— SYSTEM PARAMETERS DEPENDENCIES:
- vnfield.kafka.bootstrap_servers: Kafka cluster connection string
- vnfield.kafka.consumer_group_id: Consumer group identifier cho parallel processing
- vnfield.kafka.consumer_timeout: Polling timeout configuration
- vnfield.kafka.max_messages: Batch size control cho consumption
- vnfield.kafka.producer_retries: Error recovery configuration
- vnfield.kafka.topic_prefix: Topic naming convention Ä‘á»ƒ organize messages

ğŸ”— VNFIELD BASE DEPENDENCIES:
- vnfield.contractor: Default contractor model vá»›i is_default_contractor field
- external_id: External system mapping field cho contractor identification
- is_default_contractor: Boolean field Ä‘á»ƒ identify default contractor cho site nÃ y

ğŸ”— BUSINESS LOGIC DEPENDENCIES:
- CS-IS communication: Message exchange giá»¯a Contractor vÃ  Integration Systems
- Contractor isolation: Consumer groups isolated by contractor external_id
- Change propagation: Kafka messages Ä‘á»ƒ sync data changes across sites
- Multi-site architecture: Distributed contractor management coordination vá»›i unique IDs
- Error resilience: Robust error management vá»›i retry mechanisms vÃ  logging
- Configuration flexibility: System parameter driven configuration management
- Connection validation: Health check capabilities cho Kafka infrastructure
- Topic organization: Contractor-specific topic naming cho message routing
"""
